{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42d1f05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f39dbbf170382d3916a18285bab3d7e1",
     "grade": false,
     "grade_id": "cell-b7c133f31c7379ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Miniproyecto 3: Clasificación de animales\n",
    "\n",
    "## Entrega 3\n",
    "\n",
    "En la vision artificial, el problema de la clasificación de imagenes tiene 2 partes importantes, el descriptor y el clasificador. En las anteriores entregas ya hemos experimentado con los descriptores, una forma de explicarle a un computador las caracteristicas visuales de una imagen mediante un vector. En esta ocasión, usaremos una unica forma de describir nuestras imagenes y experimentaremos con los diferentes clasificadores que hay, SVM, Random Forest y MLP (Multi Layer Perceptron).\n",
    "\n",
    "### Parte 1: Carga de descriptores\n",
    "\n",
    "Lo que debemos hacer primero es volver nuestras imagenes vectores que nuestros computadores puedan entender. En la entrega anterior pasamos todas las imagenes de la base de datos a sus respectivos descriptores, esto es costoso computacionalmente por lo que cargaremos estos vectores para no tener que volverlos a sacar. Utilice únicamente los descritpores que mejores resultados obtuvo de la practica anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e721a90",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c64a6043c3d0966036992fc22ffa93",
     "grade": false,
     "grade_id": "cell-8cb66375a49cd51b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "num_imagenes='' #numero de imagenes de entrenamiento\n",
    "\n",
    "# Cargue aqui sus descriptores con sus respectivas labels. Asegurese de que las variables COINSIDAN. Si usted guardo primero las labels y luego los descriptores, cambie el orden\n",
    "descript_color_train,labels_color_train='','' #Lista de descriptores de color, mejor segun experimentación\n",
    "descript_shape_train,labels_shape_train='','' #Lista de descriptores de forma, mejor segun experimentación\n",
    "descript_texture_train,labels_texture_train='','' #Lista de descriptores de textura, mejor segun experimentación\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "def load_descriptors_labels(route_name):\n",
    "    route = os.path.join(route_name)\n",
    "    with open(route, 'rb') as f:\n",
    "        data = np.load(f, allow_pickle=True).item()\n",
    "    descriptors = data['descriptors']\n",
    "    labels = data['labels']\n",
    "    return descriptors, labels\n",
    "\n",
    "# el mejor fue el de 17 textones (exp. 4)\n",
    "descript_texture_train, labels_texture_train = load_descriptors_labels('train_texture_4.npy')\n",
    "# el mejor fue el de joint+lab (exp. 3)\n",
    "descript_color_train, labels_color_train = load_descriptors_labels('train_color_3.npy')\n",
    "# el mejor fue el de 14 orientaciones y 4 pixeles_por_celda (exp. 1)\n",
    "descript_shape_train, labels_shape_train = load_descriptors_labels('train_shape_1.npy')\n",
    "\n",
    "num_imagenes = len(descript_shape_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a194df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d0829cbf952c61b68abf7f294f180e8",
     "grade": true,
     "grade_id": "cell-72a8d9105528c7a7",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(descript_color_train)==len(descript_shape_train), f'Deberia tener la misma cantidad de vectores en todos los descriptores'\n",
    "assert len(descript_shape_train)==len(descript_texture_train), f'Deberia tener la misma cantidad de vectores en todos los descriptores'\n",
    "assert len(descript_color_train)==num_imagenes, f'La cantidad de imagenes en la matriz de descriptores no coinside con el numero de imagenes que usted indico'\n",
    "assert len(descript_color_train)==len(labels_color_train), 'La cantidad de labels deberian ser iguales que la cantidad de vectores de descriptores'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee470882",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6366b542017889cad3d6c74de0630e2",
     "grade": false,
     "grade_id": "cell-ab00aeb3375b4297",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Parte 2: SVM\n",
    "\n",
    "Ahora, utilizaremos un clasificador de SVM para clasificar nuestras imagenes usando los diferentes descriptores. Inicialice 4 modelos para cada descriptor (12 modelos) variando el valor C y el Kernel. Entrene sus respectivos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660a5cfd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6b6890d929bef793526c6a2d448abc8",
     "grade": false,
     "grade_id": "cell-16d711d8932cc29e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "C1='' #valor 1 para C\n",
    "C2='' #valor 2 para C\n",
    "\n",
    "kernel1='' #kernel 1\n",
    "kernel2='' #kernel 2\n",
    "\n",
    "color_model1='' #kernel 1 y C1\n",
    "color_model2='' #kernel 1 y C2\n",
    "color_model3='' #kernel 2 y C1\n",
    "color_model4='' #kernel 2 y C2\n",
    "\n",
    "shape_model1='' #kernel 1 y C1\n",
    "shape_model2='' #kernel 1 y C2\n",
    "shape_model3='' #kernel 2 y C1\n",
    "shape_model4='' #kernel 2 y C2\n",
    "\n",
    "texture_model1='' #kernel 1 y C1\n",
    "texture_model2='' #kernel 1 y C2\n",
    "texture_model3='' #kernel 2 y C1\n",
    "texture_model4='' #kernel 2 y C2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "C1 = 0.1\n",
    "C2 = 10\n",
    "\n",
    "kernel1 = 'linear'\n",
    "kernel2 = 'rbf'\n",
    "\n",
    "color_model1 = SVC(C=C1, kernel=kernel1).fit(descript_color_train, labels_color_train)\n",
    "color_model2 = SVC(C=C2, kernel=kernel1).fit(descript_color_train, labels_color_train)\n",
    "color_model3 = SVC(C=C1, kernel=kernel2).fit(descript_color_train, labels_color_train)\n",
    "color_model4 = SVC(C=C2, kernel=kernel2).fit(descript_color_train, labels_color_train)\n",
    "\n",
    "shape_model1 = SVC(C=C1, kernel=kernel1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model2 = SVC(C=C2, kernel=kernel1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model3 = SVC(C=C1, kernel=kernel2).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model4 = SVC(C=C2, kernel=kernel2).fit(descript_shape_train, labels_shape_train)\n",
    "\n",
    "texture_model1 = SVC(C=C1, kernel=kernel1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model2 = SVC(C=C2, kernel=kernel1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model3 = SVC(C=C1, kernel=kernel2).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model4 = SVC(C=C2, kernel=kernel2).fit(descript_texture_train, labels_texture_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b4c65d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25bfa89958b250c61fb74a17768aed40",
     "grade": true,
     "grade_id": "cell-584d1c49bd193a63",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model1_params_color=color_model1.get_params()\n",
    "model2_params_color=color_model2.get_params()\n",
    "model3_params_color=color_model3.get_params()\n",
    "model4_params_color=color_model4.get_params()\n",
    "\n",
    "model1_params_shape=shape_model1.get_params()\n",
    "model2_params_shape=shape_model2.get_params()\n",
    "model3_params_shape=shape_model3.get_params()\n",
    "model4_params_shape=shape_model4.get_params()\n",
    "\n",
    "model1_params_texture=texture_model1.get_params()\n",
    "model2_params_texture=texture_model2.get_params()\n",
    "model3_params_texture=texture_model3.get_params()\n",
    "model4_params_texture=texture_model4.get_params()\n",
    "\n",
    "assert not texture_model1.fit_status_, 'Su modelo de textura no esta entrenado'\n",
    "assert not shape_model1.fit_status_, 'Su modelo de forma no esta entrenado'\n",
    "assert not color_model1.fit_status_, 'Su modelo de color no esta entrenado'\n",
    "assert model1_params_color['C']==C1, f'El valor de C deberia ser {C1} y es {model1_params_color[\"C\"]}'\n",
    "assert model2_params_shape['C']==C2, f'El valor de C deberia ser {C2} y es {model2_params_shape[\"C\"]}'\n",
    "assert model3_params_texture['kernel']==kernel2, f'El kernel deberia ser {kernel2} y es {model3_params_texture[\"kernel\"]}'\n",
    "assert texture_model4.n_features_in_==len(descript_texture_train[0]), f'Usted no entreno el modelo de textura con los vectores de textura'\n",
    "assert shape_model4.n_features_in_==len(descript_shape_train[0]), f'Usted no entreno el modelo de forma con los vectores de forma'\n",
    "assert color_model4.n_features_in_==len(descript_color_train[0]), f'Usted no entreno el modelo de color con los vectores de color'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2713f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65a62814e2328fc9a7baff2c64284180",
     "grade": false,
     "grade_id": "cell-0045ff4bf80cfae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Parte 3: Random Forest\n",
    "\n",
    "Inicialice 4 modelos para cada descriptor (12 modelos) variando el valor de n_estimators y max_features. Entrene sus respectivos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fe96d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad383da126fc9ca4306ad637706ff0e",
     "grade": false,
     "grade_id": "cell-bf477d7d1b33e1af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators1='' #valor 1 para n_estimators\n",
    "n_estimators2='' #valor 2 para n_estimators\n",
    "\n",
    "max_features1='' #max_features 1\n",
    "max_features2='' #max_features 2\n",
    "\n",
    "color_model1_RF='' #max_features 1 y n_estimators 1\n",
    "color_model2_RF='' #max_features 1 y n_estimators 2\n",
    "color_model3_RF='' #max_features 2 y n_estimators 1\n",
    "color_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "shape_model1_RF='' #max_features 1 y n_estimators 1\n",
    "shape_model2_RF='' #max_features 1 y n_estimators 2\n",
    "shape_model3_RF='' #max_features 2 y n_estimators 1\n",
    "shape_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "texture_model1_RF='' #max_features 1 y n_estimators 1\n",
    "texture_model2_RF='' #max_features 1 y n_estimators 2\n",
    "texture_model3_RF='' #max_features 2 y n_estimators 1\n",
    "texture_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "n_estimators1 = 10\n",
    "n_estimators2 = 100\n",
    "\n",
    "max_features1 = 'sqrt' \n",
    "max_features2 = 'log2'\n",
    "\n",
    "color_model1_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features1).fit(descript_color_train, labels_color_train)\n",
    "color_model2_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features1).fit(descript_color_train, labels_color_train)\n",
    "color_model3_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features2).fit(descript_color_train, labels_color_train)\n",
    "color_model4_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features2).fit(descript_color_train, labels_color_train)\n",
    "\n",
    "shape_model1_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model2_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model3_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features2).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model4_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features2).fit(descript_shape_train, labels_shape_train)\n",
    "\n",
    "texture_model1_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model2_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model3_RF = RandomForestClassifier(n_estimators=n_estimators1, max_features=max_features2).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model4_RF = RandomForestClassifier(n_estimators=n_estimators2, max_features=max_features2).fit(descript_texture_train, labels_texture_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f0a563",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f30ec70592f395b9b0536774f6a705a",
     "grade": true,
     "grade_id": "cell-bc5291dd7c4ed639",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model1_params_color_RF=color_model1_RF.get_params()\n",
    "model2_params_color_RF=color_model2_RF.get_params()\n",
    "model3_params_color_RF=color_model3_RF.get_params()\n",
    "model4_params_color_RF=color_model4_RF.get_params()\n",
    "\n",
    "model1_params_shape_RF=shape_model1_RF.get_params()\n",
    "model2_params_shape_RF=shape_model2_RF.get_params()\n",
    "model3_params_shape_RF=shape_model3_RF.get_params()\n",
    "model4_params_shape_RF=shape_model4_RF.get_params()\n",
    "\n",
    "model1_params_texture_RF=texture_model1_RF.get_params()\n",
    "model2_params_texture_RF=texture_model2_RF.get_params()\n",
    "model3_params_texture_RF=texture_model3_RF.get_params()\n",
    "model4_params_texture_RF=texture_model4_RF.get_params()\n",
    "\n",
    "assert model1_params_color_RF['n_estimators']==n_estimators1, f'El valor de n_estimators deberia ser {n_estimators1} y es {model1_params_color_RF[\"n_estimators\"]}'\n",
    "assert model2_params_shape_RF['n_estimators']==n_estimators2, f'El valor de n_estimators deberia ser {n_estimators2} y es {model2_params_shape_RF[\"n_estimators\"]}'\n",
    "assert model3_params_texture_RF['max_features']==max_features2, f'El max_features deberia ser {max_features2} y es {model3_params_texture_RF[\"max_features\"]}'\n",
    "assert texture_model4_RF.n_features_in_==len(descript_texture_train[0]), f'Usted no entreno el modelo de textura con los vectores de textura'\n",
    "assert shape_model4_RF.n_features_in_==len(descript_shape_train[0]), f'Usted no entreno el modelo de forma con los vectores de forma'\n",
    "assert color_model4_RF.n_features_in_==len(descript_color_train[0]), f'Usted no entreno el modelo de color con los vectores de color'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88378adc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72d175f693e514e09b6db7235f71260b",
     "grade": false,
     "grade_id": "cell-7a1900c497db5cb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Parte 4: MLP\n",
    "\n",
    "Por ultimo, usaremos redes neuronales como un clasificador, el MLP. Las redes neuronales reciben como entrada un vector de caracteristicas y, mediante multiplicaciones matriciales, funciones de activación y el descenso del gradiente, las redes neuronales aprenden a clasificar los descriptores optimizando una función de perdida. Inicialice 4 modelos para cada descriptor (12 modelos) variando el valor de hidden_layer_sizes y learning_rate_init. Entrene sus respectivos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d88e0d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2fe0a7fcc8fd3a4b67309ca2349c9a9",
     "grade": false,
     "grade_id": "cell-565641e8f7da3569",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_layer_sizes1='' #valor 1 para hidden_layer_sizes\n",
    "hidden_layer_sizes2='' #valor 2 para hidden_layer_sizes\n",
    "\n",
    "learning_rate_init1='' #learning_rate_init 1\n",
    "learning_rate_init2='' #learning_rate_init 2\n",
    "\n",
    "color_model1_MLP='' #learning_rate_init 1 y hidden_layer_sizes1\n",
    "color_model2_MLP='' #learning_rate_init 1 y hidden_layer_sizes2\n",
    "color_model3_MLP='' #learning_rate_init 2 y hidden_layer_sizes1\n",
    "color_model4_MLP='' #learning_rate_init 2 y hidden_layer_sizes2\n",
    "\n",
    "shape_model1_MLP='' #learning_rate_init 1 y hidden_layer_sizes1\n",
    "shape_model2_MLP='' #learning_rate_init 1 y hidden_layer_sizes2\n",
    "shape_model3_MLP='' #learning_rate_init 2 y hidden_layer_sizes1\n",
    "shape_model4_MLP='' #learning_rate_init 2 y hidden_layer_sizes2\n",
    "\n",
    "texture_model1_MLP='' #learning_rate_init 1 y hidden_layer_sizes1\n",
    "texture_model2_MLP='' #learning_rate_init 1 y hidden_layer_sizes2\n",
    "texture_model3_MLP='' #learning_rate_init 2 y hidden_layer_sizes1\n",
    "texture_model4_MLP='' #learning_rate_init 2 y hidden_layer_sizes2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "hidden_layer_sizes1 = (50,)\n",
    "hidden_layer_sizes2 = (50, 50)\n",
    "\n",
    "learning_rate_init1 = 0.0001\n",
    "learning_rate_init2 = 0.001\n",
    "\n",
    "# subir max_iter?\n",
    "\n",
    "color_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_color_train, labels_color_train)\n",
    "color_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_color_train, labels_color_train)\n",
    "color_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_color_train, labels_color_train)\n",
    "color_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_color_train, labels_color_train)\n",
    "\n",
    "shape_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_shape_train, labels_shape_train)\n",
    "\n",
    "texture_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_texture_train, labels_texture_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruebas individuales de convergencia:\n",
    "\n",
    "hidden_layer_sizesP = (50,)\n",
    "learning_rate_initP = 0.001\n",
    "\n",
    "color_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_color_train, labels_color_train)\n",
    "\n",
    "shape_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_shape_train, labels_shape_train)\n",
    "\n",
    "texture_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_texture_train, labels_texture_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a6aeb7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c1580febf1a3f5bc843d240720ea5c3",
     "grade": true,
     "grade_id": "cell-bf5a3c9732d027fa",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model1_params_color_MLP=color_model1_MLP.get_params()\n",
    "model2_params_color_MLP=color_model2_MLP.get_params()\n",
    "model3_params_color_MLP=color_model3_MLP.get_params()\n",
    "model4_params_color_MLP=color_model4_MLP.get_params()\n",
    "\n",
    "model1_params_shape_MLP=shape_model1_MLP.get_params()\n",
    "model2_params_shape_MLP=shape_model2_MLP.get_params()\n",
    "model3_params_shape_MLP=shape_model3_MLP.get_params()\n",
    "model4_params_shape_MLP=shape_model4_MLP.get_params()\n",
    "\n",
    "model1_params_texture_MLP=texture_model1_MLP.get_params()\n",
    "model2_params_texture_MLP=texture_model2_MLP.get_params()\n",
    "model3_params_texture_MLP=texture_model3_MLP.get_params()\n",
    "model4_params_texture_MLP=texture_model4_MLP.get_params()\n",
    "\n",
    "assert model1_params_color_MLP['hidden_layer_sizes']==hidden_layer_sizes1, f'El valor de hidden_layer_sizes1 deberia ser {hidden_layer_sizes1} y es {model1_params_color_MLP[\"hidden_layer_sizes\"]}'\n",
    "assert model2_params_shape_MLP['hidden_layer_sizes']==hidden_layer_sizes2, f'El valor de hidden_layer_sizes1 deberia ser {hidden_layer_sizes2} y es {model2_params_shape_MLP[\"hidden_layer_sizes\"]}'\n",
    "assert model3_params_texture_MLP['learning_rate_init']==learning_rate_init2, f'El learning_rate_init deberia ser {learning_rate_init2} y es {model3_params_texture_MLP[\"learning_rate_init\"]}'\n",
    "assert texture_model4_MLP.n_features_in_==len(descript_texture_train[0]), f'Usted no entreno el modelo de textura con los vectores de textura'\n",
    "assert shape_model4_MLP.n_features_in_==len(descript_shape_train[0]), f'Usted no entreno el modelo de forma con los vectores de forma'\n",
    "assert color_model4_MLP.n_features_in_==len(descript_color_train[0]), f'Usted no entreno el modelo de color con los vectores de color'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11782e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0723afd203faaf0e0a33079a47d9886",
     "grade": false,
     "grade_id": "cell-9cf8412b5a3f5a8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Parte 5: Validación\n",
    "\n",
    "Una vez entrenados nuestros modelos, debemos validarlos para obtener el mejor de ellos, tanto en descriptor como en clasificador. Haga uso de el descriptor de sus imagenes de validación y las metricas de precisión, cobertura y F medida para evaluar todos sus modelos. Recuerde que debe validar los modelos con su respectivo descriptor (color con color, textura con textura y forma con forma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13452eb0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ebef18a2d5c2f6a301778076afd96e3",
     "grade": false,
     "grade_id": "cell-433ceab2a37de015",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo de textura encontrado en la entrega 2 fue el de 17 textones.\n",
      "El mejor modelo de color encontrado en la entrega 2 fue el de joint+lab.\n",
      "El mejor modelo de forma encontrado en la entrega 2 fue el de 14 orientaciones y 4 pixeles por celda.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "f1_manual = lambda p, c: 2*p*c/(p+c)\n",
    "\n",
    "def metricas(annots, predictions, carpeta='None', nombre_modelo='None', manual = False):\n",
    "    \n",
    "    precision = precision_score(annots, predictions, average='weighted')\n",
    "    cobertura = recall_score(annots, predictions, average='weighted')\n",
    "    f1 = f1_score(annots, predictions, average='weighted') if not manual else f1_manual(precision, cobertura)\n",
    "        \n",
    "    print()\n",
    "    print(f'El f1 de {carpeta} del modelo {nombre_modelo} es {f1}')\n",
    "    print(f'La precision de {carpeta} del modelo {nombre_modelo} es {precision}')\n",
    "    print(f'La cobertura de {carpeta} del modelo {nombre_modelo} es {cobertura}')\n",
    "    \n",
    "def nombrar_modelo(modelo):\n",
    "    name = ''\n",
    "    if isinstance(modelo, SVC):\n",
    "        name = f'SVC con C={modelo.C} y kernel={modelo.kernel}'\n",
    "    elif isinstance(modelo, RandomForestClassifier):\n",
    "        name = f'RandomForest con n_estimators={modelo.n_estimators} y max_features={modelo.max_features}'\n",
    "    elif isinstance(modelo, MLPClassifier):\n",
    "        name = f'MLP con hidden_layer_sizes={modelo.hidden_layer_sizes} y learning_rate_init={modelo.learning_rate_init}'\n",
    "    else:\n",
    "        raise Exception('Tipo de modelo inválido')\n",
    "    return name    \n",
    "    \n",
    "def predict_classifier(models, descript, labels, carpeta='None'):\n",
    "    for model in models:\n",
    "        predictions = model.predict(descript)\n",
    "        metricas(labels, predictions, carpeta=carpeta, nombre_modelo=nombrar_modelo(model))\n",
    " \n",
    "# el mejor fue el de 17 textones (exp. 4)\n",
    "descript_texture_valid, labels_texture_valid = load_descriptors_labels('valid_texture_4.npy')\n",
    "print('El mejor modelo de textura encontrado en la entrega 2 fue el de 17 textones.')\n",
    "\n",
    "# el mejor fue el de joint+lab (exp. 3)\n",
    "descript_color_valid, labels_color_valid = load_descriptors_labels('valid_color_3.npy')\n",
    "print('El mejor modelo de color encontrado en la entrega 2 fue el de joint+lab.')\n",
    "\n",
    "# el mejor fue el de 14 orientaciones y 4 pixeles_por_celda (exp. 1)\n",
    "descript_shape_valid, labels_shape_valid = load_descriptors_labels('valid_shape_1.npy')\n",
    "print('El mejor modelo de forma encontrado en la entrega 2 fue el de 14 orientaciones y 4 pixeles por celda.')\n",
    "\n",
    "# las .npy se envían en la entrega? SI\n",
    "# UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "# COVERGENCE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39ced02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probamos los modelos de COLOR:\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=linear es 0.3122619962615379\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=linear es 0.31641598598120335\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=linear es 0.336\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=linear es 0.33153887998415765\n",
      "La precision de valid del modelo SVC con C=10 y kernel=linear es 0.32371473685412766\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=linear es 0.356\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=rbf es 0.29191327698603964\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=rbf es 0.3066807753649859\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=rbf es 0.332\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=rbf es 0.4177096163846356\n",
      "La precision de valid del modelo SVC con C=10 y kernel=rbf es 0.42170364322315446\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=rbf es 0.424\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.3086939350185701\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.31439435887110306\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.316\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.32277539010560086\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.3272306397306397\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.336\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.30558523614260164\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.30726929249501067\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.316\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.32453218756761815\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.31891025432407333\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.336\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.34458970650921117\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.34370606896423544\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.364\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.33304698858144327\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.3305796717480503\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.344\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.29821203135192487\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.2995238608230212\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.308\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.32774828793977734\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.32966186425325\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.328\n",
      "\n",
      "\n",
      "Probamos los modelos de FORMA:\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=linear es 0.40799130472637524\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=linear es 0.4245606873240252\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=linear es 0.424\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=linear es 0.40799130472637524\n",
      "La precision de valid del modelo SVC con C=10 y kernel=linear es 0.4245606873240252\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=linear es 0.424\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=rbf es 0.31622871698847743\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=rbf es 0.3393365767359575\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=rbf es 0.348\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=rbf es 0.3837874968204694\n",
      "La precision de valid del modelo SVC con C=10 y kernel=rbf es 0.3955493637028676\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=rbf es 0.4\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.24375438827644633\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.25631819177990783\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.248\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.326398113528974\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.32479347752518484\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.332\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.21375901013311152\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.20863095864463851\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.228\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.30839045666113335\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.3066029752515009\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.22123698523698526\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.2267591770875353\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.316\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.31863053544908154\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.3679704432115138\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.1132764620735727\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.2180496453900709\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.2109501382789991\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.23594709144447365\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.276\n",
      "\n",
      "\n",
      "Probamos los modelos de TEXTURA:\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=linear es 0.2604255534094086\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=linear es 0.281675983436853\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=linear es 0.292\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=linear es 0.2458859793938084\n",
      "La precision de valid del modelo SVC con C=10 y kernel=linear es 0.26081670309379695\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=linear es 0.28\n",
      "\n",
      "El f1 de valid del modelo SVC con C=0.1 y kernel=rbf es 0.24031155401850782\n",
      "La precision de valid del modelo SVC con C=0.1 y kernel=rbf es 0.22158175158175158\n",
      "La cobertura de valid del modelo SVC con C=0.1 y kernel=rbf es 0.276\n",
      "\n",
      "El f1 de valid del modelo SVC con C=10 y kernel=rbf es 0.40257302677976775\n",
      "La precision de valid del modelo SVC con C=10 y kernel=rbf es 0.40433211142057723\n",
      "La cobertura de valid del modelo SVC con C=10 y kernel=rbf es 0.404\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.25511094726302264\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.25606689091009643\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=sqrt es 0.26\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.3179226835079346\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.3181394166862147\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=sqrt es 0.32\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.29076016847573394\n",
      "La precision de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.28839763757796544\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=10 y max_features=log2 es 0.3\n",
      "\n",
      "El f1 de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.29781472291149713\n",
      "La precision de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.3018621877691645\n",
      "La cobertura de valid del modelo Random Forest con n_estimators=100 y max_features=log2 es 0.296\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.2412688271752802\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.2536845466155811\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.001 es 0.292\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.268758622838171\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.2818373071528752\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.001 es 0.3\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.31395838780992225\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.3248092713260644\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50,) y learning_rate_init=0.01 es 0.332\n",
      "\n",
      "El f1 de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.31815736519297655\n",
      "La precision de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.3177929415217551\n",
      "La cobertura de valid del modelo MLP con hidden_layer_sizes=(50, 50) y learning_rate_init=0.01 es 0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models_color = [color_model1, color_model2, color_model3, color_model4, \n",
    "                color_model1_RF, color_model2_RF, color_model3_RF, color_model4_RF,\n",
    "                color_model1_MLP, color_model2_MLP, color_model3_MLP, color_model4_MLP]\n",
    "\n",
    "models_shape = [shape_model1, shape_model2, shape_model3, shape_model4,\n",
    "                shape_model1_RF, shape_model2_RF, shape_model3_RF, shape_model4_RF,\n",
    "                shape_model1_MLP, shape_model2_MLP, shape_model3_MLP, shape_model4_MLP]\n",
    "\n",
    "models_texture = [texture_model1, texture_model2, texture_model3, texture_model4, \n",
    "                  texture_model1_RF, texture_model2_RF, texture_model3_RF, texture_model4_RF,\n",
    "                  texture_model1_MLP, texture_model2_MLP, texture_model3_MLP, texture_model4_MLP]\n",
    "\n",
    "print('Probamos los modelos de COLOR:')\n",
    "predict_classifier(models_color, descript_color_valid, labels_color_valid, 'valid')\n",
    "\n",
    "print('\\n\\nProbamos los modelos de FORMA:')\n",
    "predict_classifier(models_shape, descript_shape_valid, labels_shape_valid, 'valid')\n",
    "\n",
    "print('\\n\\nProbamos los modelos de TEXTURA:')\n",
    "predict_classifier(models_texture, descript_texture_valid, labels_texture_valid, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee75aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "color_model1='' #kernel 1 y C1\n",
    "color_model2='' #kernel 1 y C2\n",
    "color_model3='' #kernel 2 y C1\n",
    "color_model4='' #kernel 2 y C2\n",
    "\n",
    "shape_model1='' #kernel 1 y C1\n",
    "shape_model2='' #kernel 1 y C2\n",
    "shape_model3='' #kernel 2 y C1\n",
    "shape_model4='' #kernel 2 y C2\n",
    "\n",
    "texture_model1='' #kernel 1 y C1\n",
    "texture_model2='' #kernel 1 y C2\n",
    "texture_model3='' #kernel 2 y C1\n",
    "texture_model4='' #kernel 2 y C2\n",
    "\n",
    "\n",
    "color_model1_RF='' #max_features 1 y n_estimators 1\n",
    "color_model2_RF='' #max_features 1 y n_estimators 2\n",
    "color_model3_RF='' #max_features 2 y n_estimators 1\n",
    "color_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "shape_model1_RF='' #max_features 1 y n_estimators 1\n",
    "shape_model2_RF='' #max_features 1 y n_estimators 2\n",
    "shape_model3_RF='' #max_features 2 y n_estimators 1\n",
    "shape_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "texture_model1_RF='' #max_features 1 y n_estimators 1\n",
    "texture_model2_RF='' #max_features 1 y n_estimators 2\n",
    "texture_model3_RF='' #max_features 2 y n_estimators 1\n",
    "texture_model4_RF='' #max_features 2 y n_estimators 2\n",
    "\n",
    "\n",
    "color_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_color_train, labels_color_train)\n",
    "color_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_color_train, labels_color_train)\n",
    "color_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_color_train, labels_color_train)\n",
    "color_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_color_train, labels_color_train)\n",
    "\n",
    "shape_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_shape_train, labels_shape_train)\n",
    "shape_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_shape_train, labels_shape_train)\n",
    "\n",
    "texture_model1_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model2_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init1).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model3_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes1, learning_rate_init=learning_rate_init2).fit(descript_texture_train, labels_texture_train)\n",
    "texture_model4_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes2, learning_rate_init=learning_rate_init2).fit(descript_texture_train, labels_texture_train)\n",
    "\"\"\"\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentación con MLP para evitar warning de convergencia\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "hidden_layer_sizes1 = (50,)\n",
    "hidden_layer_sizes2 = (50, 50)\n",
    "\n",
    "learning_rate_init1 = 0.0001\n",
    "learning_rate_init2 = 0.001\n",
    "\n",
    "hidden_layers = [(50,), (50, 50), (50, 50, 50), (50, 50, 50, 50), (100,), (100, 100), (100, 100, 100), (100, 100, 100, 100)]\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for hidden_layer in hidden_layers:\n",
    "    for learning_rate in learning_rates:\n",
    "        print(f'hidden_layer_size: {hidden_layer}, learning_rate:, {learning_rate}')\n",
    "        print('color')\n",
    "        color_model_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer, learning_rate_init=learning_rate).fit(descript_color_train, labels_color_train)\n",
    "        print('shape')\n",
    "        shape_model_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer, learning_rate_init=learning_rate).fit(descript_shape_train, labels_shape_train)\n",
    "        print('texture')\n",
    "        texture_model_MLP = MLPClassifier(hidden_layer_sizes=hidden_layer, learning_rate_init=learning_rate).fit(descript_texture_train, labels_texture_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc8eee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1512288af19a96cab60d68abfc2dc8e",
     "grade": false,
     "grade_id": "cell-46596c34ad000564",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Articulo\n",
    "\n",
    "Una vez realizado el procedimiento es fundamental que se continue con la construcción del articulo de forma progresiva, por lo cual incluiremos lo que hicimos en esta entrega.\n",
    "\n",
    "### Experimentos\n",
    "\n",
    "#### Clasificadores\n",
    "En la entrega pasada hemos experimentado con los descriptores unicamente. En esta ocasión, experimentamos con los parametros de diferentes clasificadores. Agregue los resultados de su experimentación usando los diferentes clasificadores junto con una breve descripción de sus resultados (no discusión). Puede guiarse respondiendo las siguientes preguntas:\n",
    "\n",
    "- ¿Cuál fue su mejor método?\n",
    "- ¿Hubo algún parámetro que influyera mas? (i.e. Un C mas grande en el SVM dió resultados mejores en la clasificaición que modificar el kernel.)\n",
    "- ¿Qué combinación no funcionó de forma correcta?\n",
    "- ¿Existía alguna tendencia?\n",
    "- ¿Algun clasificador tiene un desempeño mejor que el baseline, alguno tiene un desempeño peor?\n",
    "- ¿Cual clasificador funcionó mejor que el resto?\n",
    "\n",
    "### Discusión\n",
    "\n",
    "#### Clasificadores\n",
    "Incluyan un análisis de lo obtenido en sus experimentos. Tenga en cuenta resultados cuantitativos y cualitativos. Teorice sobre las mejoras o las desmejoras de los modelos. Puede guiarse respondiendo las siguientes preguntas:\n",
    "\n",
    "- ¿Algun clasificador no mejoro el baseline? ¿cual puede ser la razon?\n",
    "- ¿Cuales son los sustentos teoricos de los resultados? ¿Hay algun resultado anti-intuitivo?\n",
    "- ¿Los resultados de los descriptores son consistentes en todos los clasificadores? ¿por que?\n",
    "\n",
    "#### Metodo final\n",
    "Por ultimo, debe determinar cual es su mejor modelo de clasificación y su mejor descriptor. Haga un analisis en profundidad de la combinación de parametros y del descriptor final utilizado. Describa tambien las caracteristicas de sus resultados, tiene una alta precisión o una alta cobertura y las posibles implicaciones de esto en la vida real. \n",
    "\n",
    "### Conclusiones\n",
    "Concluya acerca de los resultados obtenidos en esta base de datos y lo novedoso de su aproximación. ¿Cree que su aproximación es suficiente? Como mejoraria su modelo para obtener mejores resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "converter(\"Entrega 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
